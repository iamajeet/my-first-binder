# Machine Learning and Data Analysis
My jupytor notebooks on machine learning and data analysis

## By using Linear Regression model  
![alt text](https://github.com/iamajeet/my-first-binder/blob/main/data/linear-regression-in-machine-learning.png)
### (Single independent variable) To Predict per capita income of CANADA in 2023.  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Fsimple_linear_regression%2Fsimple_linear_regression.ipynb)  
### (Multiple independent variable) To Predict salaries for following candidates.  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Flinear_regression_multivariate%2Flinear_regression_multivariate.ipynb)
*__2__ yr experience, **9** test score, **6** interview score*   
*__12__ yr experience, **10** test score, **10** interview score*

## By using Logistic Regression model  
![alt text](https://github.com/iamajeet/my-first-binder/blob/main/data/logistic_regrassion.png)
### (Multiclass) To classify iris flower data set to [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Flogistic_regression_multiclass%2Flogistic_regression_multiclass.ipynb)
* *Setosa*
* *Versicolour*
* *Virginica*
#### Feature list
* *Sepal Length*  
* *Sepal Width*  
* *Petal Length*  
* *Petal Width*  

### (Binary) To Predict employee retention  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Flogistic_regression_binary%2Flogistic_regression.ipynb)
*To figure out which variables have direct and clear impact on employee retention (i.e. whether they leave the company or continue to work)*  

## By using Decision Tree model  
![alt text](https://github.com/iamajeet/my-first-binder/blob/main/data/DecisionTree.png)
###  To predict survival possibilities of Titanic crash based on certain parameters.  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Fdecision_tree%2Fdecision_tree.ipynb)  
* *Pclass*
* *Sex*
* *Age*
* *Fare*
## By using Support Vector Machine model 
![alt text](https://github.com/iamajeet/my-first-binder/blob/main/data/svm.png)
### Train SVM classifier using sklearn digits dataset (i.e. from sklearn.datasets import load_digits) and then... [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/iamajeet/my-first-binder/HEAD?labpath=ML%2Fnotebooks%2Fsvm%2Fsvm.ipynb)  
* *Measure accuracy of your model using different kernels such as rbf and linear.*
* *Tune your model further using regularization and gamma parameters and try to come up with highest accurancy score*
* *Use 80% of samples as training data size*

## By using Random Forest model 
![alt text](https://github.com/iamajeet/my-first-binder/blob/main/data/how-random-forest-classifier-work.png)
### Use famous iris flower dataset from sklearn.datasets to predict flower species using random forest classifier.  
* *Measure prediction score using default n_estimators (10)*
* *Now fine tune your model by changing number of trees in your classifer and tell me what best score you can get using how many trees*  

 
    
     

 
    
    
  
  




